---
title: "Predicting Type II Diabetes and Dyslipidemia in Adults using the Composition of Dietary Fat and Carbohydrates"
author: "Ian Astalosh (450376261), Cassie Brooks (440151111), Catherine Chen (430257760), Jerry Xu (311304397), Leon Yao (460364601)"
output: pdf_document
---

```{r, include=FALSE}

#PACKAGES
#install.packages(ggplot2)
#install.packages()
#install.packages()
#library(ggplot2)
#library()
#library()

```

# Executive Summary
Cardiovascular diseases are the leading cause of death in Australia, where ischaemic heart diseases is the most common form of cardiovascular-related deaths. An emerging risk factor for cardiovascular disease include obesity, and is considered an uprising epidemic globally. Contributors towards obesity include existing health problems such as type 2 diabetes and dyslipidemia, both of which can often be predicted or controlled through diet. This paper investigates individual dietary intake patterns of Australian adults aged 18-75 years, specifically the composition of dietary fat and carbohydrates, and analysing its effect and relationship with comorbidities of obesity. Data from the Australian Health Survey and National Health Survey 2011-2012 and National Nutrition and Physical Activity Survey 2011-2012 was collaborated and reviewed. Our main research questions were:

\begin{enumerate}
\item What factors influence the chances of a person having an NCD such as type II diabetes or dyslipidemia?
\item How does the amount of dietary fat affect a person's chances of having type II diabetes or dyslipidemia?
\item How do free sugars and added sugars affect a person's chances of having type II diabetes or dyslipidemia?
\item Is it possible to predict prevalence of these diseases from only basic physical details and these dietary breakdowns?
\end{enumerate}

A positive correlation was noted between intake of carbohydrates with dyslipidemia, and trans fats be the highest indidactor compared to polyunsaturated fats, monounsaturated fats, and saturated fats. Carbohydrates and trans fats were similarly positively correlated to diabetes, while other fats did not have as significant of a link. 

## Shortcomings
\begin{itemize}
\item There was significant imbalance in the data. Most people reported not having diabetes for example, and this class imbalance caused our classifiers to struggle. 
\item There were large amounts of missingness in the data. With greater sample size we may have seen more pronounced effects, however even despite the wealth of data here it may not have been enough
\item In doing prediction, there is the implicit assumption that a person is living their life as if they did not know their diagnosis. It is reasonable to assume that someone upon learning they are diabetic is likely to change their eating habits, thus meaning their consumption data is not representative of the habits that led to them becoming diabetic in the first place. 

\end{itemize}

# Context

Non-communicable diseases (NCDs) are responsible for 41 million deaths globally each year, with cardiovascular disease accounting for 17.9 million and diabetes 1.6 million. The interplay of genetic, physiological, environmental, and behavioural factors influence and contribute to metabolic risk factors that increase the risk of NCDs.  Obesity is the excess of normal adiposity and is a highly influential risk factor in the pathophysiology of many diseases including diabetes mellitus and dyslipidemia. Obesity plays a pivotal role in the dysregulation of cellular metabolism giving rise to local insulin resistance within adipose tissue, which can have further downstream consequences. Affected adipose tissue can result in uncontrolled release of fatty acids, elevated secretion of inflammatory cytokines and adipokines that influence lipoprotein metabolism and further impact insulin sensitivity.

Diet has been shown to influence our blood lipid profile, with diets high in saturated fat, trans fats contributing to abnormally high levels of cholesterol. Furthermore, carbohydrate rich diets have been shown to contribute to type 2 diabetes mellitus, where glycemic index, an in vivo indicator of carbohydrate quality based on absorption rate, and glycemic load, a measure of effect of carbohydrates in the diet, were used as a measure to link type 2 diabetes with carbohydrates. 
 
Plasma lipoprotein particles are responsible for the transport of fat within the bloodstream, and are classified according to density, High Density Lipoprotein (HDL), Low Density Lipoprotein (LDL), Intermediate Density Lipoprotein (ILD) and Very Low Density Lipoprotein (VLDL).

This paper investigates individual dietary intake patterns of Australian adults aged 18-75 years, specifically the composition of dietary fat and carbohydrates, analysing its effect and relationship with comorbidities of obesity, namely dyslipidemia and T2D. We explore the specific effects of individual types dietary fats and carbohydrates on the characteristics of dyslipidemia and T2D. 



```{r, echo=FALSE, include=FALSE}

#PACKAGES USED IN THIS ANALYSIS. TO INSTALL SIMPLY UNCOMMENT THE LINE.

# install.packages("tidyverse")
# install.packages("tidyr")
# install.packages("dplyr")
# install.packages("broom") # for tidy()
# install.packages("ggplot2")
# install.packages("pROC")
# install.packages("plotROC")
# install.packages("gmodels") #CrossTable
# install.packages("MLmetrics")
# install.packages("ROCR")
# install.packages("e1071") # SVM
# install.packages("pscl")
# install.packages("caTools") # train_test_split
# install.packages("gridExtra") # Grid plotting for ggplot2
# install.packages("factoextra")
# install.packages("kmed")
# install.packages("cluster")
# install.packages("outliers")
# install.packages("ggbiplot")
# # install.packages("rsample")      # data splitting - not available for the most recent version of R
# install.packages("randomForestSRC") # basic RF package
# install.packages("ranger")
# install.packages("kableExtra")
# install.packages("kable")
# install.packages("reshape2")
# install.packages("corrplot")

suppressMessages(library(tidyverse))
library(tidyr)
library(dplyr)
library(broom) # for tidy()
library(ggplot2)
library(pROC)
library(plotROC)
library(gmodels) #CrossTable
library(MLmetrics)
library(ROCR)

library(e1071) # SVM

library(pscl)
library(smotefamily)
library(caTools) # train_test_split

library(gridExtra) # Grid plotting for ggplot2
library(factoextra)
library(kmed)
library(cluster)
library(outliers)
library(ggbiplot)

# library(rsample)      # data splitting - not available for the most recent version of R
library(randomForestSRC) # basic RF package
library(ranger)
library(kableExtra)
library(reshape2)
library(corrplot)

source("./functions/cv_knn.R")
source("./functions/cv_da.R")
source("./functions/cv_rpart.R")
source("./functions/cv_glm.R")
source("./functions/cv_glm_backward.R")

feature_variables = c("BMISC", "AGEC", "PHDKGWBC", "EXLWTBC", "SF2SA1QN", "INCDEC", "HSUGBC", "FATT1", "SUGART1", 
                      "PREVAT1", "PROVAT1", "FATPER1", "LAPER1", "ALAPER1", "CHOPER1", "SUGPER1", "SATPER1", 
                      "TRANPER1", "MONOPER1", "POLYPER1", "ADTOTSE", "SEX", "SMKSTAT", "SYSTOL", "FASTSTAD", 
                      "HDLCHREB", "LDLNTR", "LDLRESB", "B3T1",
                      
                      "CHOWSAT1", "STARCHT1", "FIBRET1", "FIBRPER1", "ALCT1", "ALCPER1", 
                      "PEFRESD1", "PEADDSD1")
# BMR, SLPTIME
response_variables = c("CHOLNTR", "HDLCHREB", "DIABBC", "HCHOLBC", "HYPBC", "CVDMEDST")
all_variables = c(feature_variables, response_variables)
nutm_orig = read.csv("../output/nutmstat_factors_and_NAs.csv")
nutm = nutm_orig[all_variables]

```

```{r, include=FALSE}

categoricalList <- c()
categoricalList[ 1 ] <- FALSE #  BMISC 
categoricalList[ 2 ] <- FALSE #  AGEC 
categoricalList[ 3 ] <- FALSE #  PHDKGWBC 
categoricalList[ 4 ] <- FALSE #  EXLWTBC 
categoricalList[ 5 ] <- TRUE #  SF2SA1QN 
categoricalList[ 6 ] <- TRUE #  INCDEC 
categoricalList[ 7 ] <- TRUE #  HSUGBC 
categoricalList[ 8 ] <- FALSE #  FATT1 
categoricalList[ 9 ] <- FALSE #  SUGART1 
categoricalList[ 10 ] <- FALSE #  PREVAT1 
categoricalList[ 11 ] <- FALSE #  PROVAT1 
categoricalList[ 12 ] <- FALSE #  FATPER1 
categoricalList[ 13 ] <- FALSE #  LAPER1 
categoricalList[ 14 ] <- FALSE #  ALAPER1 
categoricalList[ 15 ] <- FALSE #  CHOPER1 
categoricalList[ 16 ] <- FALSE #  SUGPER1 
categoricalList[ 17 ] <- FALSE #  SATPER1 
categoricalList[ 18 ] <- FALSE #  TRANPER1 
categoricalList[ 19 ] <- FALSE #  MONOPER1 
categoricalList[ 20 ] <- FALSE #  POLYPER1 
categoricalList[ 21 ] <- FALSE #  ADTOTSE 
categoricalList[ 22 ] <- TRUE #  SEX 
categoricalList[ 23 ] <- TRUE #  SMKSTAT 
categoricalList[ 24 ] <- FALSE #  SYSTOL 
categoricalList[ 25 ] <- TRUE #  FASTSTAD 
categoricalList[ 26 ] <- TRUE #  HDLCHREB 
categoricalList[ 27 ] <- TRUE #  LDLNTR 
categoricalList[ 28 ] <- TRUE #  LDLRESB 
categoricalList[ 29 ] <- FALSE #  B3T1
categoricalList[ 30 ] <- FALSE #  CHOWSAT1 
categoricalList[ 31 ] <- FALSE #  STARCHT1 
categoricalList[ 32 ] <- FALSE #  FIBRET1 
categoricalList[ 33 ] <- FALSE #  FIBRPER1 
categoricalList[ 34 ] <- FALSE #  ALCT1 
categoricalList[ 35 ] <- FALSE #  ALCPER1
categoricalList[ 36 ] <- FALSE #  PERFRESD1 
categoricalList[ 37 ] <- FALSE #  PEADDSD1 
categoricalList[ 38 ] <- TRUE #  CHOLNTR 
categoricalList[ 39 ] <- TRUE #  HDLCHREB 
categoricalList[ 40 ] <- TRUE #  DIABBC 
categoricalList[ 41 ] <- TRUE #  HCHOLBC 
categoricalList[ 42 ] <- TRUE #  HYPBC 
categoricalList[ 43 ] <- TRUE #  CVDMEDST 
# "CHOLNTR", "HDLCHREB", "DIABBC", "HCHOLBC", "HYPBC", "CVDMEDST"
for (i in 1:length(categoricalList)) {
  if (categoricalList[ i ]) {
      nutm[,i] <- as.factor(nutm[ ,i])
  } else {
     nutm[, i] <- as.numeric(nutm[, i])
  }
}
head(nutm)

```

# Exploratory Data Analysis

## Missing Values
The data supplied for this project from the AHS contained 12,153 instances of 144 variables. By considering only adults (ages 18+) and consulting with the nutrition students on what variables to include, our working dataset was trimmed to 9435 instances of 44 variables.  

The data firstly needed to be cleaned as there were large amounts of missingness. Our response variables of interest are DIABBC (presence of type 2 diabetes) and CVDMEDST (dyslipidemia). For variables that were identified as potential response variables, the missingness actually varied significantly:

```{r, echo=FALSE, fig=TRUE}
diabbc_miss = 100*mean(is.na(nutm$DIABBC))
dyslip_miss = 100*mean(is.na(nutm$CVDMEDST))

miss_mat = matrix(c(diabbc_miss, dyslip_miss), nrow=1)
colnames(miss_mat) = c("Diabetes", "Dyslipidemia"); rownames(miss_mat) = "Percentage Data Missing"

kabtab = kable(miss_mat)
kable_styling(kabtab)

```

We have complete responses for diabetes, however only about a quarter of respondents for dyslipidemia. We deal with missing data by only keeping the complete cases. We considered using multiple imputation methods, however the data loss is not too bad, and our sample sizes become 7567 and 2909 respectively for diabetes and dyslipidemia (from an original 9435).

## Examining our Target Variables
We now perform exploratory data analysis on our variables of interest: type II diabetes and dyslipidemia.

### Diabetes
We firstly would like to see the proportion of people in our data with our particular diseases. We collapse the DIABBC into a simple "does not have diabetes" (0) and "has diabetes" (1):

```{r, include=FALSE, echo=FALSE}
#DIABBC 
diabetes_response = c("DIABBC")
diabetes_variables = c("BMISC", "AGEC", "EXLWTBC", 
                       "SUGART1", "CHOPER1", 
                       "FATPER1", "LAPER1", "ALAPER1", 
                       "SATPER1", "TRANPER1", "MONOPER1", "POLYPER1", 
                       "ADTOTSE",
                       "SYSTOL", "B3T1",
                      "CHOWSAT1", "STARCHT1", "FIBRPER1", "ALCPER1", 
                      "PEFRESD1", "PEADDSD1"
                       )

diabetes = nutm[c(diabetes_response, diabetes_variables)]
diabetes = diabetes[diabetes$DIABBC != 3, ]

table(diabetes$DIABBC)

diabetes <- mutate(diabetes, DIABBC = ifelse(DIABBC == 5, "0", "1"))
diabetes$DIABBC <- as.factor(diabetes$DIABBC)

diabetes_no_na <- diabetes[complete.cases(diabetes), ]

dim(diabetes_no_na)
head(diabetes_no_na)
table(diabetes_no_na$DIABBC)

class_count <- table(diabetes$DIABBC)
count_mat = matrix(class_count, nrow=1)
colnames(count_mat) = c("Does not have diabetes", "Has diabetes"); rownames(count_mat) = "Number of instances"
count_mat

```

```{r, echo=FALSE}
count_diab = kable(count_mat)
kable_styling(count_diab)
```
There is a significant imbalance in the number of adults surveyed with and without diabetes. This will be an issue when performing classification later on.

We then aim to see if there are any differences in the consumption of the micronutrients and sugars of interest:
```{r, echo=FALSE, fig=TRUE, message=FALSE}
diabfats1 = diabetes_no_na[,c("DIABBC","LAPER1","SATPER1","MONOPER1","POLYPER1")]
diabfats2 = diabetes_no_na[,c("DIABBC","ALAPER1", "TRANPER1")]

diabsugars1 = diabetes_no_na[, c("DIABBC","PEFRESD1", "PEADDSD1")]

melted_diab_fats1 = melt(diabfats1)
colnames(melted_diab_fats1) = c("Has Diabetes", "Variable", "Value")
fat1 = ggplot(melted_diab_fats1, aes(x = Variable, y = Value, fill = `Has Diabetes`)) + geom_boxplot() + ggtitle("Percentage of Energy Intake from Fats") + theme(plot.title = element_text(hjust = 0.5, size=9), axis.title.x = element_text(size=8), axis.title.y = element_text(size=8), axis.text.x = element_text(size=5), legend.title = element_text(size=8))

melted_diab_fats2 = melt(diabfats2)
colnames(melted_diab_fats2) = c("Has Diabetes", "Variable", "Value")
fat2 = ggplot(melted_diab_fats2, aes(x = Variable, y = Value, fill = `Has Diabetes`)) + geom_boxplot() + ggtitle("Percentage of Energy Intake from Fats") + theme(plot.title = element_text(hjust = 0.5, size=9), axis.title.x = element_text(size=8), axis.title.y = element_text(size=8), axis.text.x = element_text(size=5), legend.title = element_text(size=8))

melted_diab_sugars1 = melt(diabsugars1)
colnames(melted_diab_sugars1) = c("Has Diabetes", "Variable", "Value")
sugar1 = ggplot(melted_diab_sugars1, aes(x = Variable, y = Value, fill = `Has Diabetes`)) + geom_boxplot() + ggtitle("Percentage of Energy Intake from Sugars") + theme(plot.title = element_text(hjust = 0.5, size=9), axis.title.x = element_text(size=8), axis.title.y = element_text(size=8), axis.text.x = element_text(size=5), legend.title = element_text(size=8))

grid.arrange(fat1, fat2, sugar1, nrow=2)
```
There are a few things to note here. Firstly, the data is skewed with a large number of outliers. With more time we would have liked to spend more time examining outliers to determine which are valid for the analysis, however we did not. Secondly, there appears to be a difference in the amount of sugar consumed by those with and without diabetes. However in terms of the dietary fats, it is difficult to spot a difference.

### Dyslipidemia
Again, we examine the counts of cases:

```{r, include=FALSE, echo=FALSE}
#DYSLIP
dyslipidemia_response = c("CVDMEDST")
dyslipidemia_variables = c("BMISC", "AGEC", "EXLWTBC", 
                       "SUGART1", "CHOPER1", 
                       "FATPER1", "LAPER1", "ALAPER1", 
                       "SATPER1", "TRANPER1", "MONOPER1", "POLYPER1", 
                       "ADTOTSE",
                       "SYSTOL", "B3T1",
                       "CHOWSAT1", "STARCHT1", "FIBRPER1", "ALCPER1",     
                       "PEFRESD1", "PEADDSD1"
                       )
dyslipidemia = nutm[c(dyslipidemia_response, dyslipidemia_variables)]
head(dyslipidemia)
dyslipidemia <- mutate(dyslipidemia, CVDMEDST = ifelse(CVDMEDST == 4, "0", "1"))
dyslipidemia$CVDMEDST <- as.factor(dyslipidemia$CVDMEDST)

dyslipidemia_no_na <- dyslipidemia[complete.cases(dyslipidemia), ]

dim(dyslipidemia_no_na)
head(dyslipidemia_no_na)
table(dyslipidemia_no_na$CVDMEDST)

class_count <- table(dyslipidemia$CVDMEDST)
count_mat_dys = matrix(class_count, nrow=1)
colnames(count_mat_dys) = c("Does not have dyslipidemia", "Has dyslipidemia"); rownames(count_mat_dys) = "Number of instances"
count_mat_dys

```

```{r, echo=FALSE}

count_dys = kable(count_mat_dys)
kable_styling(count_dys)

```

This data is slightly more balanced, however may still be problematic.

Again now we examine the data for those with and without the disease:

```{r, echo=FALSE, fig=TRUE, message=FALSE}

dyslipfats1 = dyslipidemia_no_na[,c("CVDMEDST","LAPER1","SATPER1","MONOPER1","POLYPER1")]
dyslipfats2 = dyslipidemia_no_na[,c("CVDMEDST","ALAPER1", "TRANPER1")]

dyslipsugars1 = dyslipidemia_no_na[, c("CVDMEDST","PEFRESD1", "PEADDSD1")]

melted_dyslip_fats1 = melt(dyslipfats1)
colnames(melted_dyslip_fats1) = c("Has Dyslipidemia", "Variable", "Value")
fat1 = ggplot(melted_dyslip_fats1, aes(x = Variable, y = Value, fill = `Has Dyslipidemia`)) + geom_boxplot() + ggtitle("Percentage of Energy Intake from Fats") + theme(plot.title = element_text(hjust = 0.5, size=9), axis.title.x = element_text(size=8), axis.title.y = element_text(size=8), axis.text.x = element_text(size=5), legend.title = element_text(size=8))

melted_dyslip_fats2 = melt(dyslipfats2)
colnames(melted_dyslip_fats2) = c("Has Dyslipidemia", "Variable", "Value")
fat2 = ggplot(melted_dyslip_fats2, aes(x = Variable, y = Value, fill = `Has Dyslipidemia`)) + geom_boxplot() + ggtitle("Percentage of Energy Intake from Fats") + theme(plot.title = element_text(hjust = 0.5, size=9), axis.title.x = element_text(size=8), axis.title.y = element_text(size=8), axis.text.x = element_text(size=5), legend.title = element_text(size=8))

melted_dyslip_sugars1 = melt(dyslipsugars1)
colnames(melted_dyslip_sugars1) = c("Has Dyslipidemia", "Variable", "Value")
sugar1 = ggplot(melted_dyslip_sugars1, aes(x = Variable, y = Value, fill = `Has Dyslipidemia`)) + geom_boxplot() + ggtitle("Percentage of Energy Intake from Sugars") + theme(plot.title = element_text(hjust = 0.5, size=9), axis.title.x = element_text(size=8), axis.title.y = element_text(size=8), axis.text.x = element_text(size=5), legend.title = element_text(size=8))

grid.arrange(fat1, fat2, sugar1, nrow=2)

```
There appears to be even less of a difference for dyslipidemia, suggesting this may be even harder to predict.

## Correlations among factors
We now consider the relationships between our chosen factors. These factors were chosen based on expert knkowledge, but we plot a correlogram to look for multicollinearity which may cause problems in our models. Looking at the diabetes data (the larger of our two subsets as there is less missingness):

```{r, echo=FALSE, fig.align = "center"}

forcor = diabetes_no_na[,-1]
corplot1 = cor(forcor)
corrplot(corplot1, method = "color", type = "upper", tl.col="black",  addCoef.col = "black", number.cex=0.4, tl.cex = 0.6,  insig = "blank")

```

There are again some interesting trends to be seen from this. Most variables are not corelated, except in certain sections. The fats generally have shigh corrleations, but this may be due to a 'doubling up'. For example, SATPER1 contains the percentage of energy intake from saturated fat and fatty acids, which is of course highly corrlated with TRANPER1, the percentage intake of trans-fatty acids. We also see CHOPER1, percentage of energy from carbohydrate, is highly correlated with energy sources such as sugars and starch, which makes sense. We also see the percentage energy from free sugars is highly correlated with that from added sugars.

Outside of this, there appears to be no notable correlation trends that will affect our analysis.

# Models
Although we directed our focus towards the relationship between sugars and diabetes/dyslipidemia, we also looked at the relationship between various fats to cholesterol levels as well, increasing our scope to 6 response variables. We only include the important results here, the detailed analysis can be found in the `./rmd` directory.  


## Choice of Models 
The response variables analysed fall into 3 main categories. The diabetes response variable (DIABBC), cholesterol levels (CHOLNTR), LDL cholesterol variables (LDLNTR) and dyslipidemia (CVDMEDST), are all binary outcomes, and thus we can use various straightforward classification models for prediction. 

The other 2 response variables, HDL cholesterol (HDLCHREB) and LDL cholesterol (LDLRESB) are all ordinal, categorical variables the represent a range of mmol/L concentrations from low to high. For these variables, we utilised a mixture of approaches, including the standard random forest (which we know does not reflect the relationship between the variables) as well as the more appropriate proportional odds models. 

For the modelling section, we focus on predictive power whilst still leveraging the models for inference. The random forest method was chosen as it is an extremely powerful classifcation algorithm, capable of handling different types of data and adept at preventing overfitting through its ensemble method at the relatively small cost of an increase in bias. Fitting a random forests will also give an indication of which variables are the most significant in classification, and allows comparison with other models. 

Logistic regression, alternatively, provides greater insight into the effect of each variable through its parameter estimates. While the error may be higher, we will more clearly be able to see the size and impact of the effect of each covariate. Specifically, this will enable us to examine which dietary fats and/or sugars positively and negatively impact a person's health and risk of chronic disease.


## Summary of Modelling  
The discussion begins with the less successful modelling outcomes for the binary response variables, namely LDLNTR and CHOLNTR. Despite utilising a variety of classification algorithms and hyperparameter tuning techniques, the outcome of the models were at best a random guess. This is due to the feature variables being indistinguishable between the 2 classes, resulting in a significant overlap in the n-dimensional hyperplane, making it impossible of the algorithms to learn the unique features of each class for classification. 

At the end of the all the analysis, we visualised the densities of each feature variable grouped by class and unsurprisingly, the densities were almost identical in most cases except for the age variable. We further confirmed this by running a PCA to visualise the variabilities of the data on a 2D plan by class, and again, the classes were spread evenly across the 2 most important components. This meant that there was variance in the variables, but unfortunately the distinction between the 2 classes were insufficient for modelling.

For the ordinal LDL and HDL outcomes, the same issues persisted. Both the Random Forest model, which does not reflect the relationship between the response variables, as well as proportional odds models were overly conservative and failed to predict the boundary cases for both response variables. This is partly attributed to the indistinguishable densities, but also because the parallel regression assumption does not hold as well. However, using a partial proportional odds models did not yield any significant improvements in prediction.

Now we turn to discuss the 2 remaining binary response variables, diabetes and dyslipidemia. 

### Diabetes
For diabetes, the imbalance between the 2 classes required upsampling in order to achieve an effective balance for learning. We used a straight upsampling method and a more complicated SMOTE sampling method, that replicates the data by changing it slightly using a nearest neighbours approach. As a baseline, we also tried penalised-SVM on the original, imbalanced dataset which could reduce the overall FNR and FPR despite hyperparameter tuning. 

The SMOTE upsampling method was the most successful. We witheld a test set from the original data as evaluation, and used a train-test split approach to train the models. 

We were able to achieve an acceptable FNR & FPR trade-off of $\approx$ 30\% respectively after tuning the probability threshold hyperparameter for the logistic regression model.

```{r, echo=FALSE}

set.seed(10)

sample_sub = sample.split(diabetes_no_na$DIABBC, SplitRatio = .7)
train_diabetes = subset(diabetes_no_na, sample_sub == TRUE)
test_diabetes  = subset(diabetes_no_na, sample_sub == FALSE)

SMOTE_data <- SMOTE(train_diabetes[, -1], train_diabetes[, 1], 
      dup_size=10, K = 7)

names(SMOTE_data$data)[names(SMOTE_data$data) == 'class'] <- "DIABBC"

df_len <- dim(diabetes_no_na)[2]

diabetes_upsample <- data.frame(cbind("DIABBC" = SMOTE_data$data$DIABBC, SMOTE_data$data[, 1:(df_len-1)]))

logistic_regression = glm(DIABBC~., family=binomial, data=diabetes_upsample)
summary(logistic_regression)

probs_tuning <- seq(0.05, 0.95, by=0.05)

accuracy <- c()
fpr <- c()
fnr <- c()
f1 <- c()

for (i in 1:length(probs_tuning) ){
  
    test_tuning_logit <- predict(logistic_regression, newdata=test_diabetes, type='response')
    test_tuning_logit <- ifelse(test_tuning_logit > probs_tuning[i], 1, 0)
    
    table_results <- table(test_diabetes$DIABBC, test_tuning_logit)
    
    accuracy[i] <- (table_results[1] + table_results[4])/sum(table_results)
    fpr[i] <- table_results[3]/(table_results[1] + table_results[3])
    fnr[i] <- table_results[2]/(table_results[2] + table_results[4])
}

tuning_results <- data.frame(cbind(probs_tuning, "accuracy" = accuracy*100, "FPR" = fpr*100, "FNR" = fnr*100, "F1" = f1))

ggplot(tuning_results, aes(x=fnr, y=fpr)) + geom_point(colour="orange", size=2.5) + xlab("False Positive Rate %") + ylab("False Negative Rate %") +
  theme_minimal()

```

```{r, echo=FALSE}

prob_threshold = 0.40
diabetes_true_test <- predict(logistic_regression, newdata = test_diabetes, type='response')
diabetes_true_test <- ifelse(diabetes_true_test > prob_threshold, 1, 0)
diabetes_cm <- table(test_diabetes$DIABBC, diabetes_true_test)
diabetes_cm

print(paste("Accuracy : ", (diabetes_cm[1] + diabetes_cm[4])/sum(diabetes_cm) ))
print(paste("FPR : ", diabetes_cm[3]/(diabetes_cm[1] + diabetes_cm[3]) ))
print(paste("FNR : ", diabetes_cm[2]/(diabetes_cm[2] + diabetes_cm[4]) ))
print(paste("F1 score: ", F1_Score(test_diabetes$DIABBC, diabetes_true_test)))

```

```{r}

set.seed(10)

diabetes_rf <- ranger(
  formula = DIABBC ~ .,
  data    = diabetes_upsample,
  importance = "impurity"
  # xtest   = test$y,
  # ytest   = test[, 2:df_len]
)

diabetes_rf$variable.importance %>% 
  tidy() %>%
  dplyr::arrange(desc(x)) %>%
  dplyr::top_n(25) %>%
  ggplot(aes(reorder(names, x), x)) +
  geom_col(fill="orange") + theme_minimal() +
  coord_flip() +
  ggtitle("Most important variables for Diabetes")

```

```{r, echo=FALSE}

diabetes_true_test_rf <- predict(diabetes_rf, data = test_diabetes)
diabetes_cm <- table(test_diabetes$DIABBC, diabetes_true_test_rf$predictions)
diabetes_cm 


print(paste("Accuracy : ", (diabetes_cm[1] + diabetes_cm[4])/sum(diabetes_cm) ))
print(paste("FPR : ", diabetes_cm[3]/(diabetes_cm[1] + diabetes_cm[3]) ))
print(paste("FNR : ", diabetes_cm[2]/(diabetes_cm[2] + diabetes_cm[4]) ))
print(paste("F1 score: ", F1_Score(test_diabetes$DIABBC, diabetes_true_test_rf$predictions)))

```

The random forest model was not able to achieve the same performance for the FNR. 

### Dyslipidemia
With dyslipidemia, the classes were more balanced, meaning that using upsampling techniques were not necessary. In this case, the logistic regression were able to find a compromise of $\approx$30\% given the optimal probability threshold used to classify the outcomes. 

```{r, echo=FALSE}

set.seed(10)

X = data.frame(dyslipidemia_no_na[, 2:df_len])
y = dyslipidemia_no_na$CVDMEDST

logistic_regression = glm(y~., family=binomial, data=X)
summary(logistic_regression)

sample_sub = sample.split(dyslipidemia_no_na$CVDMEDST, SplitRatio = 0.7)
train_dyslip = subset(dyslipidemia_no_na, sample_sub == TRUE)
test_dyslip  = subset(dyslipidemia_no_na, sample_sub == FALSE)

probs_tuning <- seq(0.05, 0.95, by=0.05)

accuracy <- c()
fpr <- c()
fnr <- c()
f1 <- c()

for (i in 1:length(probs_tuning) ){
    test_tuning_logit <- predict(logistic_regression, newdata=test_dyslip, type='response')
    test_tuning_logit <- ifelse(test_tuning_logit > probs_tuning[i], 1, 0)
    table_results <- table(test_dyslip$CVDMEDST, test_tuning_logit)
    
    
    accuracy[i] <- (table_results[1] + table_results[4])/sum(table_results)
    fpr[i] <- table_results[3]/(table_results[1] + table_results[3])
    fnr[i] <- table_results[2]/(table_results[2] + table_results[4])
}

tuning_results <- data.frame(cbind(probs_tuning, accuracy, fpr, fnr, f1))

ggplot(tuning_results, aes(x=fnr, y=fpr)) + geom_point(colour="orange", size=2.5) + xlab("False Positive Rate %") + ylab("False Negative Rate %") +
  theme_minimal()


```

```{r}

prob_threshold = 0.70

test_predictions_logit <- predict(logistic_regression, newdata=test_dyslip, type='response')
test_predictions_logit <- ifelse(test_predictions_logit > prob_threshold, 1, 0)

dyslip_cm <- table(test_dyslip$CVDMEDST, test_predictions_logit)
dyslip_cm

print(paste("Accuracy : ", (dyslip_cm[1] + dyslip_cm[4])/sum(dyslip_cm) ))
print(paste("FPR : ", dyslip_cm[3]/(dyslip_cm[1] + dyslip_cm[3]) ))
print(paste("FNR : ", dyslip_cm[2]/(dyslip_cm[2] + dyslip_cm[4]) ))
print(paste("F1 score: ", F1_Score(test_dyslip$CVDMEDST, dyslip_true_test_rf$predictions) ))

```

The random forest model produced too much 

```{r, echo=FALSE}

dyslip_rf <- ranger(
  formula = CVDMEDST ~ .,
  data    = train_dyslip,
  importance = "impurity"
)

dyslip_rf$variable.importance %>% 
  tidy() %>%
  dplyr::arrange(desc(x)) %>%
  dplyr::top_n(30) %>%
  ggplot(aes(reorder(names, x), x)) +
  geom_col(fill = "orange") +
  coord_flip() + theme_minimal()
  ggtitle("Most important variables for Diabetes")

```

```{r}

dyslip_true_test_rf <- predict(dyslip_rf, data = test_dyslip)
dyslip_cm <- table(test_dyslip$CVDMEDST, dyslip_true_test_rf$predictions)
dyslip_cm

print(paste("Accuracy : ", (dyslip_cm[1] + dyslip_cm[4])/sum(dyslip_cm) ))
print(paste("FPR : ", dyslip_cm[3]/(dyslip_cm[1] + dyslip_cm[3]) ))
print(paste("FNR : ", dyslip_cm[2]/(dyslip_cm[2] + dyslip_cm[4]) ))
print(paste("F1 score: ", F1_Score(test_dyslip$CVDMEDST, dyslip_true_test_rf$predictions) ))

```


# Discussion




# References


