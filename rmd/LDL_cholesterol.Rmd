---
title: "LDL_cholesterol"
author: "Jerry Xu"
date: "18 October 2018"
output: html_document
---

## Summary

Similar to the cholesterol case, none of the variables here had sufficient difference between the 2 classes to allow the algorithms to learn from the features to distinguish between them. At the end of the all the analysis, we visualised the densities of each feature variable grouped by class and unsurprisingly, the densities were almost identical in most cases except for the age variable. We further confirmed this by running a PCA to visualise the variabilities of the data on a 2D plan by class, and again, the classes were spread evenly across the 2 most important components. 

## Predicting Abnormal Levels of LDL Cholesterol

Warning: The glm functions take a while to run. They have been commented out to save time when running the whole file.

```{r, include=FALSE}

# library(tidyverse)
library(tidyr)
library(dplyr)
library(broom) # for tidy()
library(ggplot2)
library(pROC)
library(plotROC)
library(gmodels) #CrossTable
library(MLmetrics)
library(ROCR)

library(e1071) # SVM

library(pscl)
library(caTools) # train_test_split

library(gridExtra) # Grid plotting for ggplot2
library(factoextra)
library(kmed)
library(cluster)
library(outliers)
library(ggbiplot)

# library(rsample)      # data splitting - not available for the most recent version of R
library(randomForestSRC) # basic RF package
library(ranger)

source("./functions/cv_knn.R")
source("./functions/cv_da.R")
source("./functions/cv_rpart.R")
source("./functions/cv_glm.R")
source("./functions/cv_glm_backward.R")

```

## Standardised Preprocessing

```{r}

feature_variables = c("BMISC", "AGEC", "PHDKGWBC", "EXLWTBC", "SF2SA1QN", "INCDEC", "HSUGBC", "FATT1", "SUGART1", 
                       "PREVAT1", "PROVAT1", "FATPER1", "LAPER1", "ALAPER1", "CHOPER1", "SUGPER1", "SATPER1", "TRANPER1", 
                       "MONOPER1", "POLYPER1", "ADTOTSE", "SEX", "SMKSTAT", "SYSTOL", "FASTSTAD", "HDLCHREB", "LDLNTR", "LDLRESB", "B3T1")

# BMR, SLPTIME

response_variables = c("CHOLNTR", "HDLCHREB", "DIABBC", "HCHOLBC", "HYPBC", "CVDMEDST")

all_variables = c(feature_variables, response_variables)

nutm_orig = read.csv("../output/nutmstat_factors_and_NAs.csv")
nutm = nutm_orig[all_variables]

```

We'll need to reprocess some of the variables as factors. 

```{r}
categoricalList <- c()

categoricalList[ 1 ] <- FALSE #  BMISC 
categoricalList[ 2 ] <- FALSE #  AGEC 

categoricalList[ 3 ] <- FALSE #  PHDKGWBC 

categoricalList[ 4 ] <- FALSE #  EXLWTBC 

categoricalList[ 5 ] <- TRUE #  SF2SA1QN 
categoricalList[ 6 ] <- TRUE #  INCDEC 

categoricalList[ 7 ] <- TRUE #  HSUGBC 

categoricalList[ 8 ] <- FALSE #  FATT1 

categoricalList[ 9 ] <- FALSE #  SUGART1 

categoricalList[ 10 ] <- FALSE #  PREVAT1 
categoricalList[ 11 ] <- FALSE #  PROVAT1 

categoricalList[ 12 ] <- FALSE #  FATPER1 
categoricalList[ 13 ] <- FALSE #  LAPER1 
categoricalList[ 14 ] <- FALSE #  ALAPER1 
categoricalList[ 15 ] <- FALSE #  CHOPER1 
categoricalList[ 16 ] <- FALSE #  SUGPER1 

categoricalList[ 17 ] <- FALSE #  SATPER1 
categoricalList[ 18 ] <- FALSE #  TRANPER1 

categoricalList[ 19 ] <- FALSE #  MONOPER1 
categoricalList[ 20 ] <- FALSE #  POLYPER1 
categoricalList[ 21 ] <- FALSE #  ADTOTSE 

categoricalList[ 22 ] <- TRUE #  SEX 

categoricalList[ 23 ] <- TRUE #  SMKSTAT 
categoricalList[ 24 ] <- FALSE #  SYSTOL 

categoricalList[ 25 ] <- TRUE #  FASTSTAD 

categoricalList[ 26 ] <- TRUE #  HDLCHREB 
categoricalList[ 27 ] <- TRUE #  LDLNTR 
categoricalList[ 28 ] <- TRUE #  LDLRESB 

categoricalList[ 29 ] <- FALSE #  B3T1

categoricalList[ 30 ] <- TRUE #  CHOLNTR 
categoricalList[ 31 ] <- TRUE #  HDLCHREB 
categoricalList[ 32 ] <- TRUE #  DIABBC 
categoricalList[ 33 ] <- TRUE #  HCHOLBC 
categoricalList[ 34 ] <- TRUE #  HYPBC 
categoricalList[ 35 ] <- TRUE #  CVDMEDST 

# "CHOLNTR", "HDLCHREB", "DIABBC", "HCHOLBC", "HYPBC", "CVDMEDST"

for (i in 1:length(categoricalList)) {
  if (categoricalList[ i ]) {
      nutm[,i] <- as.factor(nutm[ ,i])
  }
}

head(nutm)
```

#### Data Preprocessing Stage

Let's firstly check how much data we have.

```{r}

nutm = filter(nutm, AGEC > 17)

sum(is.na(nutm["LDLNTR"]))
table(nutm["LDLNTR"])

```

We have a selection of variables that were filtered collectively by the group. Depending on the response variable. We shall subset these variables even further. 

```{r}

cholesterol_response = c("LDLNTR")
cholesterol_variables = c("BMISC", "AGEC", 
                       #"EXLWTBC", 
                       # "SF2SA1QN", "INCDEC",
                       # "HSUGBC", 
                       "FATT1", "SUGART1", 
                       "FATPER1", "LAPER1", "ALAPER1", "CHOPER1", 
                       "SATPER1", "TRANPER1", "MONOPER1", "POLYPER1", 
                       # "ADTOTSE",
                       # "SEX"
                       # "SMKSTAT", 
                       "SYSTOL", 
                       # "FASTSTAD", 
                       # "HDLCHREB", 
                       # "LDLNTR", 
                       # "LDLRESB", 
                       "B3T1"
                       )

cholesterol = nutm[c(cholesterol_response, cholesterol_variables)]

cholesterol <- mutate(cholesterol, LDLNTR = ifelse(LDLNTR == 1, "0", "1"))
cholesterol$LDLNTR <- as.factor(cholesterol$LDLNTR)
# cholesterol$HDLCHREB <- as.numeric(cholesterol$HDLCHREB)
# cholesterol$LDLNTR <- as.numeric(cholesterol$LDLNTR)
# cholesterol$LDLRESB <- as.numeric(cholesterol$LDLRESB)
head(cholesterol)

```

We simply remove all rows were the null values exist. This does not cause us any major issues in both the size of the observed data and distortion of the proportion of the 2 classes.

```{r}

cholesterol_no_na <- cholesterol[complete.cases(cholesterol), ]
dim(cholesterol_no_na)

table(cholesterol_no_na$LDLNTR)

1873/(1051+1873)

```

We check the null accuracy, which is 64%. 

Setting variables:

```{r}

df_len = dim(cholesterol_no_na)[2] # no. of columns in Dataframe 
df_len

neighbours = 3
V = 10 # cross-validation splits. 

```

```{r}

X = data.frame(scale(cholesterol_no_na[, 2:df_len]))
y = cholesterol_no_na$LDLNTR

cv_knn(X, y, k=neighbours, V=10, seed=1)

k_neighbours = seq(1,15,by=2)
cv_errors = c()
for (i in 1:length(k_neighbours)) {
  cv_errors[i] = cv_knn(X, as.factor(y),k=k_neighbours[i],V,seed=1)
}
plot(k_neighbours, cv_errors, type="l", xlab="value of k", ylab="cross-validation error", cex.lab=1.5,
    main="CV errors for K-nearest neighbours", cex.main=2, ylim=c(0.2,0.60))

```

It seems like K-nearest neighbours performs even worse than the baseline. This is indeed baffling, which suggests that the 2 classes are close in the vector space and difficult to distinguish. 

### LDA and QDA

```{r}

X = data.frame(scale(cholesterol_no_na[, 2:15]))
y = cholesterol_no_na$LDLNTR

cv_da(X = X, y = y, V = 10, method = "lda", seed = 1)
cv_da(X = X, y = y, V = 10, method = "qda", seed = 1)

```

The KNN and Discriminant Analysis algorithms fail to perform. 

```{r}

X <- as.matrix(cholesterol_no_na[, 2:df_len])
y <- cholesterol_no_na$LDLNTR
cholesterol_no_na_cart <- data.frame(y, X)

res_rpart <- rpart(y ~ X
, data=cholesterol_no_na,  method="class")
rpart.plot(res_rpart,type=1,extra=1, main="CART for LDL Cholesterol, non_zeroes")

summary(res_rpart)

print("The cross-validation accuracy is:")
cv_rpart(X, y, V, seed=1)

```

Both the KNN and CART algorithms fail to perform. We now turn Random Forests, which partitions the dataset in both samples and features - increasing bias slightly in compensation to a considerable reduction in variance. 

However, the fact that the decision tree failed to split at ANY node given 14 variables indicates just how much overlap there is, in this dataset. 

#### Random Forests

```{r}

X = data.frame(cholesterol_no_na[, 2:df_len])
y = cholesterol_no_na$LDLNTR

cholesterol_no_na_cart <- data.frame(y, X)

sample_sub = sample.split(cholesterol_no_na_cart$y, SplitRatio = 0.7)
train = subset(cholesterol_no_na_cart, sample_sub == TRUE)
test  = subset(cholesterol_no_na_cart, sample_sub == FALSE)
table(train$y)
table(test$y)

```

```{r}

chol_train <- ranger(
  formula = y ~ .,
  data    = train,
  importance = "impurity",
  class.weights=c("0"=1, "1"=2.5),
  classification=TRUE
  # xtest   = test$y,
  # ytest   = test[, 2:df_len]
)

chol_train$variable.importance
chol_train$prediction.error

print("Predict using the test set")
chol_test <- predict(chol_train, data = test)

CrossTable(test$y, chol_test$predictions)

chol_train$variable.importance %>% 
  tidy() %>%
  dplyr::arrange(desc(x)) %>%
  dplyr::top_n(25) %>%
  ggplot(aes(reorder(names, x), x)) +
  geom_col() +
  coord_flip() +
  ggtitle("Top 25 important variables")

```

```{r}

chol_train$confusion.matrix

```


Based on the confusion matrix, the accuracy is 

```{r}

table_results <- table(test$y, chol_test$predictions)
(table_results[1] + table_results[4])/sum(table_results)*100

```

There was no increase in prediction accuracy compared to the first 2 algorithms we used. It seems that the data is indeed poorly separated, and that none of the variables are good indicators to levels of LDL cholesterol. 

```{r}

roc <- roc(response=as.numeric(chol_test$predictions), predictor=as.numeric(test$y))
auc <- auc(response=as.numeric(test$y), predictor=as.numeric(chol_test$predictions))
plot(roc)

roc
auc

```

__Tuning the Hyperparameters__

```{r, eval=FALSE, include=FALSE}

hyper_grid_2 <- expand.grid(
  mtry       = seq(5, 14, by = 2),
  node_size  = seq(3, 8, by = 2),
  sampe_size = c(.55, .632, .70),
  OOB_RMSE  = 0
)

hyper_grid_2

# perform grid search
for(i in 1:nrow(hyper_grid_2)) {
  
  # train model
  model <- ranger(
    formula         = y ~ ., 
    data            = train, 
    importance      = "impurity",
    num.trees       = 500,
    mtry            = hyper_grid_2$mtry[i],
    min.node.size   = hyper_grid_2$node_size[i],
    sample.fraction = hyper_grid_2$sampe_size[i],
    seed            = 123
  )
  
  # add OOB error to grid
  hyper_grid_2$OOB_RMSE[i] <- sqrt(model$prediction.error)
}

hyper_grid_2 %>% 
  dplyr::arrange(OOB_RMSE) %>%
  head(10)

```

#### GLMs

```{r, include=TRUE}

X = data.frame(cholesterol_no_na[, 2:df_len])
y = cholesterol_no_na$LDLNTR

# mutate(cholesterol_no_na, LDLNTR = ifelse(LDLNTR == "0", 0, 1))

logistic_regression = glm(y~., family=binomial, data=X)
summary(logistic_regression)

```

```{r}

anova(logistic_regression)
pR2(logistic_regression) # Look at McFadden

```

```{r}

cv_glm(X, y, V = 10)

```


__Testing Prediction Capabilities for Logistic Regression__

Now let's test how well this model performs.

```{r}

sample_sub = sample.split(cholesterol_no_na_cart$y, SplitRatio = 0.7)
train = subset(cholesterol_no_na_cart, sample_sub == TRUE)
test  = subset(cholesterol_no_na_cart, sample_sub == FALSE)
head(train)
head(test)

prob_threshold = 0.30

chol_test_pred <- predict(logistic_regression, newdata=test, type='response')
chol_test_pred <- ifelse(chol_test_pred > prob_threshold, "1", "0")

CrossTable(test$y, chol_test_pred)

misClasificError <- mean(chol_test_pred != test$y)
print(paste('Accuracy: ',1-misClasificError))

print(paste("F1 score: ", F1_Score(test$y, chol_test_pred)))

```

Now let's try to conduct some cross-validation on GLMs. 

```{r, eval=FALSE, include=FALSE}

cv_glm_backward(X, y, V = 10, pen = log(df_samples))
cv_glm_backward(X, y, V = 10, pen = 2)

```

## Support Vector Machines

```{r}
cholesterol_no_na
train
```

```{r}
cholesterol_no_na
```


```{r}

class_weights = c(1, 1.75)

#cholesterol_no_na <- mutate(cholesterol_no_na, LDLNTR = ifelse(LDLNTR == "1", 1, 0))

sample_sub = sample.split(cholesterol_no_na$LDLNTR, SplitRatio = 0.7)
train = subset(cholesterol_no_na, sample_sub == TRUE)
test  = subset(cholesterol_no_na, sample_sub == FALSE)
head(train)
head(test)

svm_model <- svm(LDLNTR ~ ., data=train, kernel="polynomial",
                 coef0=1,
                 gamma=0.1,
                 cost=0.1,
                 class.weights=c("0"=class_weights[1], "1"=class_weights[2])
                 )
summary(svm_model)

test_pred <- predict(svm_model, test[, -1])
test_pred[1:10]

```

```{r}

CrossTable(test$LDLNTR, test_pred)

table_results <- table(test$LDLNTR, test_pred)

print("Accuracy:")
(table_results[1]+table_results[4])/sum(table_results)*100

print("F1_score:")
F1_Score(test$LDLNTR, test_pred)

```

## Visualising Variables 

Due to the poor results, we want to check whether the variables are differentiable individually. If they are not, then this means none of the variables independently are huge influencers of LDL cholesterol prediction, and we turn to multi-dimensional methods such as PCA to see whether the data has good variance and can be separated.

### Density Plots

```{r}

df <- cholesterol_no_na

density_bmi <- ggplot(df, aes(x = df$BMISC, fill = LDLNTR)) +
  geom_density(alpha = 0.5) +
    scale_fill_discrete(labels=c("0", "1")) + guides(fill=guide_legend(title=NULL)) +
      geom_vline(xintercept = mean(df$BMISC, na.rm=TRUE), linetype="dashed", color="black", size=1) +
        xlab("BMISC")

density_age <- ggplot(df, aes(x = df$AGEC, fill = LDLNTR)) +
  geom_density(alpha = 0.5) +
    scale_fill_discrete(labels=c("0", "1")) + guides(fill=guide_legend(title=NULL)) +
      geom_vline(xintercept = mean(df$AGEC, na.rm=TRUE), linetype="dashed", color="black", size=1) +
        xlab("AGEC")

density_fat <- ggplot(df, aes(x = df$FATT1, fill = LDLNTR)) +
  geom_density(alpha = 0.5) +
    scale_fill_discrete(labels=c("0", "1")) + guides(fill=guide_legend(title=NULL)) +
      geom_vline(xintercept = mean(df$FATT1, na.rm=TRUE), linetype="dashed", color="black", size=1) +
        xlab("FATT1")

density_sugar <- ggplot(df, aes(x = df$SUGART1, fill = LDLNTR)) +
  geom_density(alpha = 0.5) +
    scale_fill_discrete(labels=c("0", "1")) + guides(fill=guide_legend(title=NULL)) +
      geom_vline(xintercept = mean(df$SUGART1, na.rm=TRUE), linetype="dashed", color="black", size=1) +
        xlab("SUGART1")

density_fat_precent <- ggplot(df, aes(x = df$FATPER1, fill = LDLNTR)) +
  geom_density(alpha = 0.5) +
    scale_fill_discrete(labels=c("0", "1")) + guides(fill=guide_legend(title=NULL)) +
      geom_vline(xintercept = mean(df$FATPER1, na.rm=TRUE), linetype="dashed", color="black", size=1) +
        xlab("FATPER1")

density_linoleic <- ggplot(df, aes(x = df$LAPER1, fill = LDLNTR)) +
  geom_density(alpha = 0.5) +
    scale_fill_discrete(labels=c("0", "1")) + guides(fill=guide_legend(title=NULL)) +
      geom_vline(xintercept = mean(df$LAPER1, na.rm=TRUE), linetype="dashed", color="black", size=1) +
        xlab("LAPER1")

density_alpha_linoleic <- ggplot(df, aes(x = df$ALAPER1, fill = LDLNTR)) +
  geom_density(alpha = 0.5) +
    scale_fill_discrete(labels=c("0", "1")) + guides(fill=guide_legend(title=NULL)) +
      geom_vline(xintercept = mean(df$ALAPER1, na.rm=TRUE), linetype="dashed", color="black", size=1) +
        xlab("ALAPER1")

density_carbo_percent <- ggplot(df, aes(x = df$CHOPER1, fill = LDLNTR)) +
  geom_density(alpha = 0.5) +
    scale_fill_discrete(labels=c("0", "1")) + guides(fill=guide_legend(title=NULL)) +
      geom_vline(xintercept = mean(df$CHOPER1, na.rm=TRUE), linetype="dashed", color="black", size=1) +
        xlab("CHOPER1")

density_sat_percent <- ggplot(df, aes(x = df$SATPER1, fill = LDLNTR)) +
  geom_density(alpha = 0.5) +
    scale_fill_discrete(labels=c("0", "1")) + guides(fill=guide_legend(title=NULL)) +
      geom_vline(xintercept = mean(df$SATPER1, na.rm=TRUE), linetype="dashed", color="black", size=1) +
        xlab("SATPER1")

density_trans_fat_percent <- ggplot(df, aes(x = df$TRANPER1, fill = LDLNTR)) +
  geom_density(alpha = 0.5) +
    scale_fill_discrete(labels=c("0", "1")) + guides(fill=guide_legend(title=NULL)) +
      geom_vline(xintercept = mean(df$TRANPER1, na.rm=TRUE), linetype="dashed", color="black", size=1) +
        xlab("TRANPER1")

density_mono_fat_percent <- ggplot(df, aes(x = df$MONOPER1, fill = LDLNTR)) +
  geom_density(alpha = 0.5) +
    scale_fill_discrete(labels=c("0", "1")) + guides(fill=guide_legend(title=NULL)) +
      geom_vline(xintercept = mean(df$MONOPER1, na.rm=TRUE), linetype="dashed", color="black", size=1) +
        xlab("MONOPER1")

density_poly_fat_percent <- ggplot(df, aes(x = df$POLYPER1, fill = LDLNTR)) +
  geom_density(alpha = 0.5) +
    scale_fill_discrete(labels=c("0", "1")) + guides(fill=guide_legend(title=NULL)) +
      geom_vline(xintercept = mean(df$POLYPER1, na.rm=TRUE), linetype="dashed", color="black", size=1) +
        xlab("POLYPER1")

density_systol <- ggplot(df, aes(x = df$SYSTOL, fill = LDLNTR)) +
  geom_density(alpha = 0.5) +
    scale_fill_discrete(labels=c("0", "1")) + guides(fill=guide_legend(title=NULL)) +
      geom_vline(xintercept = mean(df$SYSTOL, na.rm=TRUE), linetype="dashed", color="black", size=1) +
        xlab("SYSTOL")

density_niacin <- ggplot(df, aes(x = df$B3T1, fill = LDLNTR)) +
  geom_density(alpha = 0.5) +
    scale_fill_discrete(labels=c("0", "1")) + guides(fill=guide_legend(title=NULL)) +
      geom_vline(xintercept = mean(df$B3T1, na.rm=TRUE), linetype="dashed", color="black", size=1) +
        xlab("B3T1")

grid.arrange(density_bmi, density_age, density_fat, 
             density_sugar, density_fat_precent, density_linoleic, 
             density_alpha_linoleic, density_carbo_percent, density_sat_percent,
             density_trans_fat_percent, density_mono_fat_percent, density_poly_fat_percent,
             density_systol, density_niacin,
             nrow = 5, ncol = 3)

```

As we suspected, the variables partitioned by class are barely distinguishable. It is no wonder then, that the models fails to have any meaningful increase in accuracy.

### Principal Component Analysis

```{r}

chol_cluster <- cholesterol_no_na[, 2:df_len]
nutm_cluster_int <- data.frame(scale(chol_cluster))

```


```{r}

nutm_pca <- princomp(nutm_cluster_int, cor=TRUE)
summary(nutm_pca)

```

```{r}

nutm_pca$sdev[1:10]
nutm_pca$scores[1:20, 1:2]

```

```{r}

apply(nutm_cluster_int, 2, cor, nutm_pca$scores[, 1]) # apply for df over columns, FUNC=cor and you're correlating with nutm_pca scores.

```

```{r}

plot(nutm_pca, type="l", main="PCA for LDL Cholesterol Feature Variables")

```

```{r}

head(cholesterol_no_na)

k_pca <- ggbiplot(nutm_pca, obs.scale = 1, var.scale = 1,
                  groups = cholesterol_no_na$CHOLNTR,
                  varname.size = 2, labels.size = 2,
                  ellipse = TRUE, circle = TRUE
                  ) + 
  scale_color_manual(name="Class", values=c("black", "red")) +
  theme(legend.direction ="horizontal", 
        legend.position = "top")

print(k_pca)

```

There appears to be variance within the feature variables itself, but the majority of the variance exists in both classes, and will be difficult to distingiush and predict. Much of the correlated variance comes from the various fats, but it is in the end unable to separate the data effectively. 

```{r, eval=FALSE, include=FALSE}

### K-means & K-mediods Clustering

nutm_kmeans = kmeans(nutm_cluster_int, 2, iter.max=10, nstart=10)

fviz_cluster(nutm_kmeans, data=nutm_cluster_int, 
             ellipse.type = "norm", palette = "Set2",
             ggtheme=theme_minimal(), ellipse.alpha = 0.2, 
             )
# This is unsupervised and thus the algorithm will produce 2 clusters anyway. This is not reflective of the classes itself. The PCA visualises the overlap of the classes much better. 

```
